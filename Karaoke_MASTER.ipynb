{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "[DEV] Karaoke-MASTER.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asigalov61/Karaoke-MASTER/blob/main/Karaoke_MASTER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QA0W-VK1JVQl"
      },
      "source": [
        "# Karaoke MASTER (ver. 1.0)\n",
        "\n",
        "***\n",
        "\n",
        "## GPT2-based Karaoke Melody Artificial Intelligence Model Creator/Trainer.\n",
        "\n",
        "***\n",
        "\n",
        "Credit for char-based GPT2 implementation used in this colab goes out to Andrej Karpathy: https://github.com/karpathy/minGPT\n",
        "\n",
        "***\n",
        "\n",
        "WARNING: This complete implementation is a functioning model of the Artificial Intelligence. Please excercise great humility, care, and respect.\n",
        "\n",
        "***\n",
        "\n",
        "##### Project Los Angeles\n",
        "\n",
        "##### Tegridy Code 2021\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eftzIVKrqR5S"
      },
      "source": [
        "# Setup Environment, clone needed repos, and install all required dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsUtsJGNz6f2",
        "cellView": "form"
      },
      "source": [
        "#@title Install all dependencies (run only once per session)\n",
        "!git clone https://github.com/asigalov61/minGPT\n",
        "!git clone https://github.com/asigalov61/tegridy-tools\n",
        "!apt install fluidsynth #Pip does not work for some reason. Only apt works\n",
        "!pip install midi2audio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pf8B3p6QySmE",
        "cellView": "form"
      },
      "source": [
        "#@title Import all needed modules\n",
        "\n",
        "print('Loading needed modules. Please wait...')\n",
        "import os\n",
        "import copy\n",
        "\n",
        "from operator import itemgetter\n",
        "from itertools import groupby\n",
        "\n",
        "os.chdir('/content/tegridy-tools/tegridy-tools')\n",
        "import TMIDI\n",
        "\n",
        "if not os.path.exists('/content/Dataset'):\n",
        "    os.makedirs('/content/Dataset')\n",
        "\n",
        "os.chdir('/content/minGPT')\n",
        "\n",
        "# make deterministic\n",
        "from mingpt.utils import set_seed\n",
        "set_seed(42)\n",
        "\n",
        "import tqdm.auto\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import time\n",
        "import math\n",
        "import datetime\n",
        "from datetime import datetime\n",
        "\n",
        "from mingpt.model import GPT, GPTConfig\n",
        "from mingpt.trainer import Trainer, TrainerConfig\n",
        "from mingpt.utils import sample\n",
        "\n",
        "import tqdm.auto\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from midi2audio import FluidSynth\n",
        "from IPython.display import display, Javascript, HTML, Audio\n",
        "\n",
        "from google.colab import output, drive\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
        "\n",
        "print('Available Processing Device is:', device)\n",
        "print('Loading complete. Enjoy! :)')\n",
        "\n",
        "os.chdir('/content/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2Pv5eNRqiyr"
      },
      "source": [
        "# Download and process MIDI dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHuggjW7etzZ",
        "cellView": "form"
      },
      "source": [
        "#@title Download Tiny Karaoke MIDI dataset\n",
        "\n",
        "#@markdown Works best stand-alone/as-is for the optimal results\n",
        "%cd /content/Dataset/\n",
        "!wget 'https://github.com/asigalov61/Tegridy-MIDI-Dataset/raw/master/Tiny-Karaoke-MIDI-Dataset-CC-BY-NC-SA.zip'\n",
        "!unzip -j '/content/Dataset/Tiny-Karaoke-MIDI-Dataset-CC-BY-NC-SA.zip'\n",
        "!rm '/content/Dataset/Tiny-Karaoke-MIDI-Dataset-CC-BY-NC-SA.zip'\n",
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1ypXZoySkHJ"
      },
      "source": [
        "# If you are not sure where to start or what settings to select, please use original defaults"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRy0VfpFIpaj",
        "cellView": "form"
      },
      "source": [
        "#@title Process MIDIs to special MIDI dataset with Tegridy MIDI Processor\n",
        "\n",
        "full_path_to_output_dataset_to = \"/content/Karaoke-MASTER\" #@param {type:\"string\"}\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "print('TMIDI Processor')\n",
        "print('Starting up...')\n",
        "\n",
        "events_list = []\n",
        "events_matrix = []\n",
        "\n",
        "###########\n",
        "\n",
        "files_count = 0\n",
        "\n",
        "ev = 0\n",
        "\n",
        "chords_list_f = []\n",
        "melody_list_f = []\n",
        "\n",
        "print('Loading MIDI files...')\n",
        "print('This may take a while on a large dataset in particular.')\n",
        "\n",
        "dataset_addr = \"/content/Dataset/\"\n",
        "os.chdir(dataset_addr)\n",
        "filez = os.listdir(dataset_addr)\n",
        "\n",
        "print('Processing MIDI files. Please wait...')\n",
        "for f in tqdm.auto.tqdm(filez):\n",
        "  files_count += 1\n",
        "  #print('Loading MIDI file...')\n",
        "  midi_file = open(f, 'rb')\n",
        "  \n",
        "  try:\n",
        "    opus = TMIDI.midi2opus(midi_file.read())\n",
        "  \n",
        "  except:\n",
        "    print('Bad file. Skipping...')\n",
        "    print('File name:', f)\n",
        "    midi_file.close()\n",
        "    continue\n",
        "        \n",
        "  midi_file.close()\n",
        "  itrack = 1\n",
        "  score1 = TMIDI.to_millisecs(opus)\n",
        "  score = TMIDI.opus2score(score1)\n",
        "  events_list = []\n",
        "  #print('Reading all MIDI events from the MIDI file...')\n",
        "  while itrack < len(score):\n",
        "    for event in score[itrack]:\n",
        "      if event[0] == 'text_event':\n",
        "        event.extend([0, 127, 0])\n",
        "        events_list.append(event) \n",
        "      if event[0] == 'note':\n",
        "        events_list.append(event)       \n",
        "      ev += 1\n",
        "    \n",
        "    itrack +=1 # Going to next track...\n",
        "\n",
        "  evt = sorted(events_list, key=itemgetter(1))\n",
        "  groups = [list(g) for _,g in groupby(evt,itemgetter(1))]\n",
        "\n",
        "  events_matrix.extend(groups)\n",
        "\n",
        "TMIDI.Tegridy_Pickle_File_Writer(events_matrix, full_path_to_output_dataset_to)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOgzhY62rESM",
        "cellView": "form"
      },
      "source": [
        "#@title Convert MIDI dataset to the Reduced TXT Karaoke dataset\n",
        "\n",
        "#@markdown Make sure to select the right encoding for your language. Encoding is correct when you can properly and clearly read it in your language. Encodings list is located here: https://docs.python.org/3/library/codecs.html#standard-encodings\n",
        "\n",
        "full_path_to_TXT_dataset = \"/content/Karaoke-MASTER_TXT_Dataset.txt\" #@param {type:\"string\"}\n",
        "karaoke_language_encoding = \"utf_8\" #@param {type:\"string\"}\n",
        "dataset_name = \"DATASET=Karaoke-MASTER_TXT_Dataset\"\n",
        "\n",
        "f_matrix = []\n",
        "final_matrix = []\n",
        "for items in events_matrix: \n",
        "  if len(items) > 0: # Removing single note events\n",
        "    it = []\n",
        "    \n",
        "    it.extend(items)\n",
        "    it.sort(reverse=True, key=lambda x: x[4]) # Sorting events by pitch\n",
        "    f_matrix.append(it) \n",
        "\n",
        "'''for items in f_matrix:\n",
        "  if items[0][0] == 'text_event':\n",
        "    final_matrix.append(items[0:2])'''\n",
        "\n",
        "p_matrix = []\n",
        "delta = 0\n",
        "items = []\n",
        "it = []\n",
        "it1 = []\n",
        "\n",
        "for items in f_matrix:\n",
        "  if items[0][0] == 'text_event' and len(items) > 1:\n",
        "    it = copy.deepcopy(items[1])\n",
        "    it.extend([0])\n",
        "    it[3] = 0\n",
        "    it[6] = items[0][2]\n",
        "    p_matrix.append(it)\n",
        "\n",
        "  if items[0][0] == 'text_event' and len(items) == 1:  \n",
        "    if items[0][2] != '' and it != []:    \n",
        "      it1 = copy.deepcopy(it)\n",
        "      it1.extend([0])\n",
        "      it1[1] = items[0][1]\n",
        "      it1[6] = items[0][2]\n",
        "      p_matrix.append(it1)\n",
        "\n",
        "pp_matrix = []\n",
        "for p in p_matrix:\n",
        "  if p[0] != 'text_event':\n",
        "    pp_matrix.append(p)\n",
        "\n",
        "ptime = 0\n",
        "time = 0\n",
        "delta = 0\n",
        "output_song = []\n",
        "\n",
        "for n in range(len(pp_matrix)-1):\n",
        "  no = copy.deepcopy(pp_matrix[n])\n",
        "\n",
        "  no[1] = int(delta / 10)\n",
        "  no[2] = int(no[2] / 10)\n",
        "  no[5] = no[4]\n",
        "\n",
        "  ptime = pp_matrix[n][1]\n",
        "  time = pp_matrix[n+1][1]\n",
        "  '''if abs(time - ptime) < 1600:\n",
        "    delta += abs(time - ptime)\n",
        "  else:\n",
        "    delta += 1600'''\n",
        "  delta = abs(time-ptime)    \n",
        "\n",
        "  output_song.append(no)\n",
        "\n",
        "output_string = ''\n",
        "\n",
        "for note in output_song:\n",
        " if note[1] < 256 and note[2] < 256: \n",
        "  output_string += chr(note[1])\n",
        "  output_string += chr(note[2])\n",
        "  output_string += chr(note[4])\n",
        "  output_string += '='\n",
        "  output_string += str(note[6].decode(karaoke_language_encoding, 'replace')).replace('/', '').replace(' ', '')\n",
        "  output_string += '\\n'\n",
        "\n",
        "TXT = dataset_name + '\\n' + output_string\n",
        "\n",
        "TMIDI.Tegridy_TXT_Dataset_File_Writer(full_path_to_TXT_dataset, '', TXT)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cj2xl5xqwea"
      },
      "source": [
        "# Setup and Intialize the Model\r\n",
        "\r\n",
        "## YOU MUST RUN ALL CELLS/CODE IN THIS SECTION to init the model. Does not matter if the model is empty or pre-trained.\r\n",
        "\r\n",
        "## DO NOT EXECUTE TRAIN CELL/CODE UNLESS YOU INTEND TO TRAIN FROM SCRATCH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1MQDOVMySmJ",
        "cellView": "form"
      },
      "source": [
        "#@title Setup functions and procedures\n",
        "model_attention_span_in_tokens = 512 #@param {type:\"slider\", min:0, max:1024, step:16}\n",
        "\n",
        "class CharDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, block_size):\n",
        "        chars = sorted(list(set(data)))\n",
        "        data_size, vocab_size = len(data), len(chars)\n",
        "        print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
        "        \n",
        "        self.stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "        self.itos = { i:ch for i,ch in enumerate(chars) }\n",
        "        self.block_size = block_size\n",
        "        self.vocab_size = vocab_size\n",
        "        self.data = data\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.block_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # grab a chunk of (block_size + 1) characters from the data\n",
        "        chunk = self.data[idx:idx + self.block_size + 1]\n",
        "        # encode every character to an integer\n",
        "        dix = [self.stoi[s] for s in chunk]\n",
        "        \n",
        "        x = torch.tensor(dix[:-1], dtype=torch.long)\n",
        "        y = torch.tensor(dix[1:], dtype=torch.long)\n",
        "        return x, y\n",
        "\n",
        "        \n",
        "block_size = model_attention_span_in_tokens # spatial extent of the model for its context"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4QIgbe3ySmN",
        "cellView": "form"
      },
      "source": [
        "#@title Specify full path to the processed TMIDI-TXT dataset file\n",
        "full_path_to_training_text_file = \"/content/Karaoke-MASTER_TXT_Dataset.txt\" #@param {type:\"string\"}\n",
        "text = open(full_path_to_training_text_file, 'r').read() # don't worry we won't run out of file handles\n",
        "train_dataset = CharDataset(text, block_size) # one line of poem is roughly 50 characters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpNxwzNkySmQ",
        "cellView": "form"
      },
      "source": [
        "#@title Create GPT2 model\n",
        "model_embed_size = 256 #@param {type:\"slider\", min:0, max:1024, step:64}\n",
        "number_of_heads = 16 #@param {type:\"slider\", min:1, max:16, step:1}\n",
        "number_of_layers = 4 #@param {type:\"slider\", min:1, max:16, step:1}\n",
        "\n",
        "\n",
        "mconf = GPTConfig(train_dataset.vocab_size, \n",
        "                  train_dataset.block_size,\n",
        "                  n_layer=number_of_layers, \n",
        "                  n_head=number_of_heads, \n",
        "                  n_embd=model_embed_size)\n",
        "\n",
        "model = GPT(mconf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWaOS0sRySmS",
        "cellView": "form"
      },
      "source": [
        "#@title Setup all training parameters\n",
        "number_of_training_epochs = 3 #@param {type:\"slider\", min:1, max:5, step:1}\n",
        "training_batch_size = 48 #@param {type:\"slider\", min:0, max:160, step:4}\n",
        "model_learning_rate = 6e-4 #@param {type:\"number\"}\n",
        "# initialize a trainer instance and kick off training\n",
        "\n",
        "tconf = TrainerConfig(max_epochs=number_of_training_epochs, \n",
        "                      batch_size=training_batch_size, \n",
        "                      learning_rate=model_learning_rate,\n",
        "                      num_workers=4)\n",
        "trainer = Trainer(model, train_dataset, None, tconf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_18H-M-q4CB"
      },
      "source": [
        "# Train the model or Load/Re-load the existing pre-trained model checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRffqT9WFBHB",
        "cellView": "form"
      },
      "source": [
        "#@title (OPTION 1) Train the model\n",
        "%cd /content/\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVWEhUj1cg7N",
        "cellView": "form"
      },
      "source": [
        "#@title Plot Positional Embeddings\n",
        "\n",
        "# visualize some of the learned positional embeddings, maybe they contain structure\n",
        "plt.figure(figsize=(18, 1))  \n",
        "ci = model.pos_emb.data[0, :, 0].cpu()\n",
        "zci = torch.cat((torch.tensor([0.0]), ci)) # pre-cat a zero\n",
        "plt.imshow(zci.view(1, block_size+1).numpy())\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMkyEMghC-KR",
        "cellView": "form"
      },
      "source": [
        "#@title Save/Re-Save the model from memory\n",
        "#@markdown Standard PyTorch AI models file extension is PTH\n",
        "full_path_to_save_model_to = \"/content/Karaoke-MASTER-Trained-Model.pth\" #@param {type:\"string\"}\n",
        "%cd /content/\n",
        "torch.save(model, full_path_to_save_model_to)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmD7VRZhDcnJ",
        "cellView": "form"
      },
      "source": [
        "#@title (OPTION 2) Load existing model/checkpoint\n",
        "full_path_to_model_checkpoint = \"/content/Karaoke-MASTER-Trained-Model.pth\" #@param {type:\"string\"}\n",
        "model = torch.load(full_path_to_model_checkpoint)\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfgeQl8_rEox"
      },
      "source": [
        "# Generate, download, plot, and listen to the output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZEqKJ6NySmV",
        "cellView": "form"
      },
      "source": [
        "#@title Generate and download the composition as TXT file.\n",
        "#@markdown PLEASE NOTE IMPORTANT POINTS: \n",
        "\n",
        "#@markdown 0) If you are not sure where to start/what settings to set, please use original defaults.\n",
        "\n",
        "#@markdown 1) Model primes from the dataset !!!\n",
        "\n",
        "#@markdown 2) Model's first output may be empty or garbled so please try several times before discarting the model\n",
        "\n",
        "print('Karaoke MASTER Model Generator')\n",
        "print('Starting up...')\n",
        "number_of_tokens_to_generate = 2048 #@param {type:\"slider\", min:0, max:32768, step:128}\n",
        "creativity_temperature = 0.8 #@param {type:\"slider\", min:0.05, max:4, step:0.05}\n",
        "top_k_prob = 4 #@param {type:\"slider\", min:0, max:50, step:1}\n",
        "input_prompt = \"Happy Days\" #@param {type:\"string\"}\n",
        "\n",
        "debug = False \n",
        "\n",
        "os.chdir('/content/')\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "context = input_prompt\n",
        "x = torch.tensor([train_dataset.stoi[s] for s in context], dtype=torch.long)[None,...].to(trainer.device)\n",
        "y = sample(model, x, number_of_tokens_to_generate, temperature=creativity_temperature, sample=True, top_k=top_k_prob)[0]\n",
        "completion = ''.join([train_dataset.itos[int(i)] for i in y])\n",
        "\n",
        "fname = TMIDI.Tegridy_File_Time_Stamp('/content/Karaoke-MASTER-Composition-')\n",
        "\n",
        "print('Done!')\n",
        "print('Saving to', str(fname + '.txt'))\n",
        "with open(fname + '.txt', \"w\") as text_file:\n",
        "    print(completion, file=text_file)\n",
        "\n",
        "print('Downloading TXT file...')\n",
        "from google.colab import files\n",
        "files.download(fname + '.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1E1cICZ9QtF",
        "cellView": "form"
      },
      "source": [
        "#@title Convert generated Karaoke TXT file to the Karaoke MIDI file\n",
        "text_encoding = \"utf_8\" #@param {type:\"string\"}\n",
        "\n",
        "print('Karaoke TXT to Karaoke MIDI Processor')\n",
        "print('Coverting your file. Please stand-by...')\n",
        "\n",
        "out_string = completion\n",
        "\n",
        "o_str = out_string.split('\\n')\n",
        "\n",
        "song_name = o_str[0]\n",
        "\n",
        "song = []\n",
        "\n",
        "show_text = ''\n",
        "\n",
        "ptime = 0\n",
        "\n",
        "for st in o_str:\n",
        "  note = ['note', 0, 0, 0, 0, 0]\n",
        "  text = ['text_event', 0, '']\n",
        "  if len(st.split('=')[0]) == 3 and len(st) > 4:\n",
        "    note[1] = ptime * 10\n",
        "    note[2] = ord(st.split('=')[0][1]) * 10\n",
        "    note[4] = ord(st.split('=')[0][2])\n",
        "    note[5] = ord(st.split('=')[0][2])\n",
        "    text[1] = ptime * 10\n",
        "    text[2] = str(st.split('=')[1])\n",
        "    ptime += ord(st.split('=')[0][0])\n",
        "    song.append(note)\n",
        "    song.append(text)\n",
        "    show_text += str(st.split('=')[1]) + ' '\n",
        "\n",
        "print('Saving your Karaoke MIDI file...')\n",
        "TMIDI.Tegridy_SONG_to_MIDI_Converter(song, output_file_name=fname, output_signature='Karaoke-MASTER', track_name=song_name, text_encoding=text_encoding)\n",
        "print('Downloading your Karaoke MIDI file...')\n",
        "from google.colab import files\n",
        "files.download(fname + '.mid')\n",
        "\n",
        "print('Task complete! Enjoy :)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "guq5UDgsE3L-"
      },
      "source": [
        "#@title Show generated Karaoke Text\n",
        "show_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kILhoHR7JmmS",
        "cellView": "form"
      },
      "source": [
        "#@title Listen to the last generated composition\n",
        "#@markdown NOTE: May be very slow with the long compositions\n",
        "print('Synthesizing the last output MIDI. Please stand-by... ')\n",
        "FluidSynth(\"/usr/share/sounds/sf2/FluidR3_GM.sf2\", 16000).midi_to_audio(str(fname + '.mid'), str(fname + '.wav'))\n",
        "Audio(str(fname + '.wav'), rate=16000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Snu3fb4N-Nd"
      },
      "source": [
        "## Congrats! :) You did it :)"
      ]
    }
  ]
}